{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment:\n",
    "\n",
    "Explore the dataset and build a model that can accept the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torchnet.meter import AverageValueMeter\n",
    "import torch.backends.cudnn as cudnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_dir': './selfdrivingcar-data/',\n",
    "    'nb_epoch': 50,\n",
    "    'test_size': 0.1,\n",
    "    'learning_rate': 0.0001,\n",
    "    'samples_per_epoch': 64,\n",
    "    'batch_size': 36,\n",
    "    'cuda': True,\n",
    "    'seed': 7\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(os.path.join(os.getcwd(), args.data_dir, 'driving_log.csv'), names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
    "\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    #we'll store the camera images as our input data\n",
    "    X = data_df[['center', 'left', 'right']].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df['steering'].values\n",
    "\n",
    "    #now we can split the data into a training (80), testing(20), and validation set\n",
    "    #thanks scikit learn\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=args.test_size, random_state=0, shuffle=True)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Lambda(lambda x: x/127.5 - 1)                                    \n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_set = CarDataset(X_train, y_train, args.data_dir, False,transformations)\n",
    "train_set = CarDataset3Img(X_train, y_train, args.data_dir,transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_set = CarDataset(X_valid, y_valid, args.data_dir, False, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(valid_set, batch_size=args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### NVIDIA Model\n",
    "    Image normalization to avoid saturation and make gradients work better.\n",
    "    Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "    Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "    Drop out (0.5)\n",
    "    Fully connected: neurons: 100, activation: ELU\n",
    "    Fully connected: neurons: 50, activation: ELU\n",
    "    Fully connected: neurons: 10, activation: ELU\n",
    "    Fully connected: neurons: 1 (output)\n",
    "    \n",
    "    the convolution layers are meant to handle feature engineering\n",
    "    the fully connected layer for predicting the steering angle.\n",
    "    dropout avoids overfitting\n",
    "    ELU(Exponential linear unit) function takes care of the Vanishing gradient problem. \n",
    "    \n",
    "### Simple Model\n",
    "\n",
    "```\n",
    "  (module): CarSimpleModel (\n",
    "    (conv_layers): Sequential (\n",
    "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "      (1): ELU (alpha=1.0)\n",
    "      (2): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "      (3): MaxPool2d (size=(4, 4), stride=(4, 4), dilation=(1, 1))\n",
    "      (4): Dropout (p = 0.25)\n",
    "    )\n",
    "    (linear_layers): Sequential (\n",
    "      (0): Linear (3648 -> 50)\n",
    "      (1): ELU (alpha=1.0)\n",
    "      (2): Linear (50 -> 10)\n",
    "      (3): Linear (10 -> 1)\n",
    "    )\n",
    "  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toVariable(data, use_cuda):\n",
    "    input, target = data\n",
    "    input, target = Variable(input.float()), Variable(target.float())\n",
    "    if use_cuda:\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "    \n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, net, dataloader, optimizer, criterion, use_cuda):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (centers, lefts, rights) in enumerate(dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        centers, lefts, rights = toVariable(centers, use_cuda), \\\n",
    "                                 toVariable(lefts, use_cuda), \\\n",
    "                                 toVariable(rights, use_cuda)\n",
    "        datas = [lefts, rights, centers]        \n",
    "        for data in datas:\n",
    "            imgs, targets = data\n",
    "            outputs = net(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.data[0]\n",
    "            \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Loss: %.3f '\n",
    "                % (train_loss/((batch_idx+1)*3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(epoch, net, validloader, criterion, use_cuda):\n",
    "    global best_loss\n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "        inputs, targets = Variable(inputs.float()), Variable(targets.float())\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        valid_loss += loss.data[0]\n",
    "        \n",
    "        avg_valid_loss = valid_loss/(batch_idx+1)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Valid Loss: %.3f '\n",
    "                % (valid_loss/(batch_idx+1)))\n",
    "        if avg_valid_loss <= best_loss:\n",
    "            best_loss = avg_valid_loss\n",
    "            print('Best epoch: ' + str(epoch))\n",
    "            state = {\n",
    "                'net': net.module if args.cuda else net,\n",
    "            }\n",
    "            torch.save(state, './model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = CarSimpleModel()\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.learning_rate)\n",
    "\n",
    "if args.cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_loss = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(0,15):\n",
    "    #optimizer = lr_scheduler(optimizer, epoch, lr_decay_epoch=args.lr_decay_epoch)\t\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    train(epoch, net, train_loader, optimizer, criterion, args.cuda)\n",
    "    valid(epoch, net, valid_loader, criterion, args.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = {\n",
    "        'net': net.module if args.cuda else net,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(state, './model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
